{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gwvXtrcvxZ01"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class expert(nn.Module):\n",
        "    def __init__(self,path=\"initial_weights.pth\"):\n",
        "        super(expert, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "        #self._initialize_weights()\n",
        "        if os.path.exists(path):\n",
        "          self.load_weights(path)\n",
        "        else:\n",
        "          self._log_initial_weights()\n",
        "\n",
        "    def _log_initial_weights(self):\n",
        "      initial_weights = {name: param.clone().detach() for name, param in self.named_parameters()}\n",
        "      torch.save(initial_weights, 'initial_weights.pth')\n",
        "      print(\"Initial weights saved to 'initial_weights.pth'\")\n",
        "\n",
        "    def load_weights(self,path):\n",
        "      weights = torch.load('initial_weights.pth')\n",
        "      for name, param in self.named_parameters():\n",
        "          param.data.copy_(weights[name])\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Ip1i6VTXxfRX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "network = expert().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(network.parameters(),lr=0.001)\n",
        "\n",
        "loss_list = []\n",
        "N_epochs = 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-k1v7sNxrfu",
        "outputId": "effc56f5-e896-4fbb-bba3-425cdc23cbfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Initial weights saved to 'initial_weights.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_epochs):\n",
        "     combined_loss = 0\n",
        "     for inputs,labels in train_loader:\n",
        "         inputs = inputs.to(device)\n",
        "         labels = F.one_hot(labels,num_classes=10).float().to(device)\n",
        "         #print(labels)\n",
        "         #input()\n",
        "         pred = network(inputs)\n",
        "         loss = criterion(pred,labels)\n",
        "         combined_loss = combined_loss + loss.item()\n",
        "         optim.zero_grad()\n",
        "         loss.backward()\n",
        "         optim.step()\n",
        "     loss_list.append(combined_loss)\n",
        "     print(\"epoch:\",epoch,\"loss:\",combined_loss)\n",
        "\n",
        "print(\"Training complete\")\n",
        "path = \"./single_expert_model\"\n",
        "torch.save(network, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "savSoF7v-ZDe",
        "outputId": "753ae2af-a0d2-488b-9ac0-2dadc36280a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 732.3535149097443\n",
            "epoch: 1 loss: 609.5219674110413\n",
            "epoch: 2 loss: 566.2838814258575\n",
            "epoch: 3 loss: 535.9174718856812\n",
            "epoch: 4 loss: 510.3687844276428\n",
            "epoch: 5 loss: 492.48207956552505\n",
            "epoch: 6 loss: 474.77973771095276\n",
            "epoch: 7 loss: 457.45296412706375\n",
            "epoch: 8 loss: 444.54776549339294\n",
            "epoch: 9 loss: 433.0480182170868\n",
            "epoch: 10 loss: 419.88516598939896\n",
            "epoch: 11 loss: 412.8006114959717\n",
            "epoch: 12 loss: 400.78377175331116\n",
            "epoch: 13 loss: 392.8532781600952\n",
            "epoch: 14 loss: 384.0487329363823\n",
            "epoch: 15 loss: 376.6059029698372\n",
            "epoch: 16 loss: 369.9014803171158\n",
            "epoch: 17 loss: 362.9875689148903\n",
            "epoch: 18 loss: 354.13904958963394\n",
            "epoch: 19 loss: 348.69776314496994\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check(pred,labels,corr):\n",
        "    pred = torch.argmax(pred,dim=1)\n",
        "    for i in range(len(pred)):\n",
        "        if pred[i] == labels[i]:\n",
        "            corr = corr + 1\n",
        "    return corr"
      ],
      "metadata": {
        "id": "audVlgeiPSzY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "corr=0\n",
        "for inputs,labels in test_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #print(labels)\n",
        "    pred = network(inputs)\n",
        "    corr = check(pred,labels,corr)\n",
        "print(\"accuracy:\",corr/len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qVojp9M-nEG",
        "outputId": "0beaa6a5-7036-498e-d50c-915ad5a89ebd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.6151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x0myh4v-O231"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}